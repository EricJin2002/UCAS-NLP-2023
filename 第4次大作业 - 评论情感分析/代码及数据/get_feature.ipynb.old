{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import os\n",
    "from collections import Counter, OrderedDict\n",
    "import json\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[404804, 282413, 386809, 362575, 355004, 396302, 327373, 385209, 403238, 333664, 10380, 129807, 2216, 23119, 12885, 296739, 378862, 395714, 374206, 403379, 364822, 3627, 325808, 362577, 356413, 426815, 402128, 196773, 302572, 255530, 255525, 339326, 403430, 285437, 349441, 388982, 326895, 401301, 286339, 106207, 842, 317613, 324295, 371546, 343106, 174143, 375817, 312297, 353605, 240386, 328609, 343182, 246001, 397604, 37785, 241088, 325487, 238, 237, 317675, 309311, 174043, 364450, 184725, 194877, 1671, 358570, 311, 265, 335160, 331200, 291095, 269537, 285784, 312310, 212333, 277436, 312700, 329160, 335032, 325285, 316607, 214685, 387839, 387822, 88433, 135275, 311673, 12544, 822, 207195, 1773, 254, 25961, 155359, 315375, 296109, 112151, 329906, 147068, 27364, 1743, 22759, 193378, 21900, 156591, 294880, 159725, 13603, 320224, 289101, 183957, 244008, 320218, 247977, 7843, 1014, 269090, 240562, 326, 278031, 51928, 373266, 292238, 116461, 160124, 185762, 248665, 291171, 240760, 302293, 158316, 279700, 262940, 300839, 23686, 18882, 255526, 278557, 262939, 277551, 285776, 213076, 54433, 102134, 175457, 218711, 251988, 243916, 279457, 264356, 267732, 208450, 225604, 226540, 115917, 3960, 60003, 220566, 199392, 280516, 38069, 28230, 10339, 239816, 2585, 297954, 325727, 206925, 81186, 302523, 860, 324, 362551, 96918, 107835, 326868, 43558, 326871, 333707, 328674, 1952, 335036, 253, 29883, 22505, 3302, 772, 298, 207573, 266147, 927, 269235, 58949, 160209, 293049, 248175, 331559, 294993, 245665, 109375, 175599, 175600, 323840, 295318, 330918, 328313, 296870, 301541, 273485, 331692, 148281, 185943, 114685, 194259, 1851, 18635, 883, 294878, 41488, 260680, 240038, 100403, 214272, 242216, 285666, 263750, 217300, 118335, 55770, 325585, 277554, 302189, 44123, 876, 114968, 114967, 99941, 277105, 129988, 82572, 105075, 120925, 315069, 1899, 51, 244878, 148481, 115292, 93714, 2463, 292970, 280837, 183878, 285879, 175601, 204855, 10639, 109386, 95225, 2354, 292, 43581, 3423, 2225, 766, 767, 812, 233, 212278, 175404, 218707, 227392, 203387, 174638, 12536, 891, 259, 23495, 49278, 965, 175198, 209596, 254762, 171068, 144357, 10799, 1428, 77625, 37685]\n"
     ]
    }
   ],
   "source": [
    "path = \"data\"\n",
    "with open(os.path.join(path, \"subject_id_list.json\"), \"r\") as f:\n",
    "    subject_id_list = json.load(f)\n",
    "print(subject_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Eric\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.568 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404804 done\n",
      "282413 done\n",
      "386809 done\n",
      "362575 done\n",
      "355004 done\n",
      "396302 done\n",
      "327373 done\n",
      "385209 done\n",
      "403238 done\n",
      "333664 done\n",
      "10380 done\n",
      "129807 done\n",
      "2216 done\n",
      "23119 done\n",
      "12885 done\n",
      "296739 done\n",
      "378862 done\n",
      "395714 done\n",
      "374206 done\n",
      "403379 done\n",
      "364822 done\n",
      "3627 done\n",
      "325808 done\n",
      "362577 done\n",
      "356413 done\n",
      "426815 done\n",
      "402128 done\n",
      "196773 done\n",
      "302572 done\n",
      "255530 done\n",
      "255525 done\n",
      "339326 done\n",
      "403430 done\n",
      "285437 done\n",
      "349441 done\n",
      "388982 done\n",
      "326895 done\n",
      "401301 done\n",
      "286339 done\n",
      "106207 done\n",
      "842 done\n",
      "317613 done\n",
      "324295 done\n",
      "371546 done\n",
      "343106 done\n",
      "174143 done\n",
      "375817 done\n",
      "312297 done\n",
      "353605 done\n",
      "240386 done\n",
      "328609 done\n",
      "343182 done\n",
      "246001 done\n",
      "397604 done\n",
      "37785 done\n",
      "241088 done\n",
      "325487 done\n",
      "238 done\n",
      "237 done\n",
      "317675 done\n",
      "309311 done\n",
      "174043 done\n",
      "364450 done\n",
      "184725 done\n",
      "194877 done\n",
      "1671 done\n",
      "358570 done\n",
      "311 done\n",
      "265 done\n",
      "335160 done\n",
      "331200 done\n",
      "291095 done\n",
      "269537 done\n",
      "285784 done\n",
      "312310 done\n",
      "212333 done\n",
      "277436 done\n",
      "312700 done\n",
      "329160 done\n",
      "335032 done\n",
      "325285 done\n",
      "316607 done\n",
      "214685 done\n",
      "387839 done\n",
      "387822 done\n",
      "88433 done\n",
      "135275 done\n",
      "311673 done\n",
      "12544 done\n",
      "822 done\n",
      "207195 done\n",
      "1773 done\n",
      "254 done\n",
      "25961 done\n",
      "155359 done\n",
      "315375 done\n",
      "296109 done\n",
      "112151 done\n",
      "329906 done\n",
      "147068 done\n",
      "27364 done\n",
      "1743 done\n",
      "22759 done\n",
      "193378 done\n",
      "21900 done\n",
      "156591 done\n",
      "294880 done\n",
      "159725 done\n",
      "13603 done\n",
      "320224 done\n",
      "289101 done\n",
      "183957 done\n",
      "244008 done\n",
      "320218 done\n",
      "247977 done\n",
      "7843 done\n",
      "1014 done\n",
      "269090 done\n",
      "240562 done\n",
      "326 done\n",
      "278031 done\n",
      "51928 done\n",
      "373266 done\n",
      "292238 done\n",
      "116461 done\n",
      "160124 done\n",
      "185762 done\n",
      "248665 done\n",
      "291171 done\n",
      "240760 done\n",
      "302293 done\n",
      "158316 done\n",
      "279700 done\n",
      "262940 done\n",
      "300839 done\n",
      "23686 done\n",
      "18882 done\n",
      "255526 done\n",
      "278557 done\n",
      "262939 done\n",
      "277551 done\n",
      "285776 done\n",
      "213076 done\n",
      "54433 done\n",
      "102134 done\n",
      "175457 done\n",
      "218711 done\n",
      "251988 done\n",
      "243916 done\n",
      "279457 done\n",
      "264356 done\n",
      "267732 done\n",
      "208450 done\n",
      "225604 done\n",
      "226540 done\n",
      "115917 done\n",
      "3960 done\n",
      "60003 done\n",
      "220566 done\n",
      "199392 done\n",
      "280516 done\n",
      "38069 done\n",
      "28230 done\n",
      "10339 done\n",
      "239816 done\n",
      "2585 done\n",
      "297954 done\n",
      "325727 done\n",
      "206925 done\n",
      "81186 done\n",
      "302523 done\n",
      "860 done\n",
      "324 done\n",
      "362551 done\n",
      "96918 done\n",
      "107835 done\n",
      "326868 done\n",
      "43558 done\n",
      "326871 done\n",
      "333707 done\n",
      "328674 done\n",
      "1952 done\n",
      "335036 done\n",
      "253 done\n",
      "29883 done\n",
      "22505 done\n",
      "3302 done\n",
      "772 done\n",
      "298 done\n",
      "207573 done\n",
      "266147 done\n",
      "927 done\n",
      "269235 done\n",
      "58949 done\n",
      "160209 done\n",
      "293049 done\n",
      "248175 done\n",
      "331559 done\n",
      "294993 done\n",
      "245665 done\n",
      "109375 done\n",
      "175599 done\n",
      "175600 done\n",
      "323840 done\n",
      "295318 done\n",
      "330918 done\n",
      "328313 done\n",
      "296870 done\n",
      "301541 done\n",
      "273485 done\n",
      "331692 done\n",
      "148281 done\n",
      "185943 done\n",
      "114685 done\n",
      "194259 done\n",
      "1851 done\n",
      "18635 done\n",
      "883 done\n",
      "294878 done\n",
      "41488 done\n",
      "260680 done\n",
      "240038 done\n",
      "100403 done\n",
      "214272 done\n",
      "242216 done\n",
      "285666 done\n",
      "263750 done\n",
      "217300 done\n",
      "118335 done\n",
      "55770 done\n",
      "325585 done\n",
      "277554 done\n",
      "302189 done\n",
      "44123 done\n",
      "876 done\n",
      "114968 done\n",
      "114967 done\n",
      "99941 done\n",
      "277105 done\n",
      "129988 done\n",
      "82572 done\n",
      "105075 done\n",
      "120925 done\n",
      "315069 done\n",
      "1899 done\n",
      "51 done\n",
      "244878 done\n",
      "148481 done\n",
      "115292 done\n",
      "93714 done\n",
      "2463 done\n",
      "292970 done\n",
      "280837 done\n",
      "183878 done\n",
      "285879 done\n",
      "175601 done\n",
      "204855 done\n",
      "10639 done\n",
      "109386 done\n",
      "95225 done\n",
      "2354 done\n",
      "292 done\n",
      "43581 done\n",
      "3423 done\n",
      "2225 done\n",
      "766 done\n",
      "767 done\n",
      "812 done\n",
      "233 done\n",
      "212278 done\n",
      "175404 done\n",
      "218707 done\n",
      "227392 done\n",
      "203387 done\n",
      "174638 done\n",
      "12536 done\n",
      "891 done\n",
      "259 done\n",
      "23495 done\n",
      "49278 done\n",
      "965 done\n",
      "175198 done\n",
      "209596 done\n",
      "254762 done\n",
      "171068 done\n",
      "144357 done\n",
      "10799 done\n",
      "1428 done\n",
      "77625 done\n",
      "37685 done\n"
     ]
    }
   ],
   "source": [
    "words = {}\n",
    "words_times = {}\n",
    "comment_num = {}\n",
    "for i in range(1, 11):\n",
    "    words[str(i)] = Counter()\n",
    "    words_times[str(i)] = Counter()\n",
    "    comment_num[str(i)] = 0\n",
    "for subject_id in subject_id_list:\n",
    "    with open(os.path.join(path, str(subject_id) + \".json\"), \"r\") as f:\n",
    "        subject = json.load(f)\n",
    "    for score, comment_list in subject.items():\n",
    "        if not score.isdigit():\n",
    "            continue\n",
    "        for comment in comment_list:\n",
    "            comment_num[score] += 1\n",
    "            words[score].update(set(jieba.cut(comment)))\n",
    "            words_times[score].update(jieba.cut(comment))\n",
    "    print(subject_id, \"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"output\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 1 done, sum of words_sorted: 45277\n",
      "score 2 done, sum of words_sorted: 29740\n",
      "score 3 done, sum of words_sorted: 59476\n",
      "score 4 done, sum of words_sorted: 136796\n",
      "score 5 done, sum of words_sorted: 258232\n",
      "score 6 done, sum of words_sorted: 593373\n",
      "score 7 done, sum of words_sorted: 984487\n",
      "score 8 done, sum of words_sorted: 1032365\n",
      "score 9 done, sum of words_sorted: 545528\n",
      "score 10 done, sum of words_sorted: 298699\n",
      "score 1 done, sum of words_times_sorted: 55774\n",
      "score 2 done, sum of words_times_sorted: 36657\n",
      "score 3 done, sum of words_times_sorted: 72504\n",
      "score 4 done, sum of words_times_sorted: 166764\n",
      "score 5 done, sum of words_times_sorted: 312703\n",
      "score 6 done, sum of words_times_sorted: 717163\n",
      "score 7 done, sum of words_times_sorted: 1193657\n",
      "score 8 done, sum of words_times_sorted: 1260455\n",
      "score 9 done, sum of words_times_sorted: 673660\n",
      "score 10 done, sum of words_times_sorted: 372305\n"
     ]
    }
   ],
   "source": [
    "# save words\n",
    "words_sorted={}\n",
    "for i in range(1, 11):\n",
    "    words_sorted[str(i)] = OrderedDict(words[str(i)].most_common())\n",
    "    # with open(os.path.join(output_path, \"words_from_score_\" + str(i) + \".json\"), \"w\") as f:\n",
    "        # json.dump(words_sorted[str(i)], f, ensure_ascii=False, indent=4)\n",
    "    print(\"score\", i, \"done, sum of words_sorted:\", sum(words_sorted[str(i)].values()))\n",
    "with open(os.path.join(output_path, \"words.json\"), \"w\") as f:\n",
    "    json.dump(words_sorted, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# save words_times\n",
    "words_times_sorted={}\n",
    "for i in range(1, 11):\n",
    "    words_times_sorted[str(i)] = OrderedDict(words_times[str(i)].most_common())\n",
    "    # with open(os.path.join(output_path, \"words_times_from_score_\" + str(i) + \".json\"), \"w\") as f:\n",
    "        # json.dump(words_times_sorted[str(i)], f, ensure_ascii=False, indent=4)\n",
    "    print(\"score\", i, \"done, sum of words_times_sorted:\", sum(words_times_sorted[str(i)].values()))\n",
    "with open(os.path.join(output_path, \"words_times.json\"), \"w\") as f:\n",
    "    json.dump(words_times_sorted, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_c_t len: 107818\n",
      "p_c_nt len: 107818\n"
     ]
    }
   ],
   "source": [
    "words_all = Counter()\n",
    "for i in range(1, 11):\n",
    "    words_all.update(words[str(i)])\n",
    "\n",
    "comment_num_all = sum(comment_num.values())\n",
    "\n",
    "p_c = {str(i): comment_num[str(i)] / comment_num_all for i in range(1, 11)}\n",
    "p_t = {word: num / comment_num_all for word, num in words_all.items()}\n",
    "\n",
    "p_c_t = {}\n",
    "p_c_nt = {}\n",
    "freq_threshold = 10\n",
    "for word in words_all.keys():\n",
    "    if word not in p_c_t:\n",
    "        p_c_t[word] = {}\n",
    "    if word not in p_c_nt:\n",
    "        p_c_nt[word] = {}\n",
    "    for i in range(1, 11):\n",
    "        p_c_t[word][str(i)] = words[str(i)].get(word, 0) / words_all[word]\n",
    "        p_c_nt[word][str(i)] = (comment_num[str(i)] - words[str(i)].get(word, 0)) / (comment_num_all - words_all[word])\n",
    "for word in words_all.keys():\n",
    "    p_c_t[word][\"p_t\"] = p_t[word]\n",
    "    p_c_nt[word][\"p_nt\"] = 1 - p_t[word]\n",
    "\n",
    "print(\"p_c_t len:\", len(p_c_t))\n",
    "print(\"p_c_nt len:\", len(p_c_nt))\n",
    "\n",
    "words_all_sorted = OrderedDict(words_all.most_common())\n",
    "\n",
    "with open(os.path.join(output_path, \"p_c.json\"), \"w\") as f:\n",
    "    json.dump(p_c, f, ensure_ascii=False, indent=4)\n",
    "with open(os.path.join(output_path, \"p_c_t.json\"), \"w\") as f:\n",
    "    json.dump(p_c_t, f, ensure_ascii=False, indent=4)\n",
    "with open(os.path.join(output_path, \"p_c_nt.json\"), \"w\") as f:\n",
    "    json.dump(p_c_nt, f, ensure_ascii=False, indent=4)\n",
    "with open(os.path.join(output_path, \"words_all.json\"), \"w\") as f:\n",
    "    json.dump(words_all_sorted, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_c_t = {}\n",
    "for word in words_all.keys():\n",
    "    h_c_t[word] = 0\n",
    "    for i in range(1, 11):\n",
    "        if p_c_t[word][str(i)] > 0:\n",
    "            h_c_t[word] -= p_c_t[word][\"p_t\"] * p_c_t[word][str(i)] * math.log(p_c_t[word][str(i)])\n",
    "        if p_c_nt[word][str(i)] > 0:\n",
    "            h_c_t[word] -= p_c_nt[word][\"p_nt\"] * p_c_nt[word][str(i)] * math.log(p_c_nt[word][str(i)])\n",
    "\n",
    "h_c = 0\n",
    "for i in range(1, 11):\n",
    "    h_c -= p_c[str(i)] * math.log(p_c[str(i)])\n",
    "\n",
    "ig_c_t = {}\n",
    "for word in words_all.keys():\n",
    "    ig_c_t[word] = h_c - h_c_t[word]\n",
    "\n",
    "ig_c_t = OrderedDict(sorted(ig_c_t.items(), key=lambda x: x[1], reverse=True))\n",
    "with open(os.path.join(output_path, \"ig_c_t.json\"), \"w\") as f:\n",
    "    json.dump(ig_c_t, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
